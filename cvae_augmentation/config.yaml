# Phase 1 Low-Risk Fixes - Critical Bug Fixes + Conditioning Dropout
# Philosophy: ONE reconstruction loss (like SRDRN) + KL regularization
#
# CRITICAL FIXES:
#   1. w_min=1.0 (was 0.1): Stop ignoring dry region errors → fixes drizzle everywhere
#   2. Conditioning dropout (p=0.5): Force decoder to use z → fixes posterior collapse
#   3. beta_kl=0.0005 (was 0.005): Allow latent usage → fixes diversity
#   4. Transposed convolutions: Learnable upsampling → better spatial structure

# Data paths
data_root: "/scratch/user/u.hn319322/ondemand/Downscaling/cVAE_augmentation"
outputs_root: "/scratch/user/u.hn319322/ondemand/Downscaling/cVAE_augmentation/outputs/cvae_final"

# Static maps configuration
statics:
  use_land_sea: true
  use_dist_coast: true
  use_elevation: false
  normalize_statics: true

# Model architecture - Improved capacity
model:
  d_x: 64
  in_channels_X: 6
  d_y: 256
  in_channels_Y: 1
  static_channels: 2
  d_z: 128              # DOUBLED from 64 for better diversity & prevent collapse
  H: 156
  W: 132
  base_filters: 64      # Decoder now uses transposed convs for sharper details

# Loss function - Keep it SIMPLE (single objective philosophy)
loss:
  type: "simplified"  # Use SimplifiedCVAELoss - NO new loss components

  # Intensity weighting - Moderately improved
  # P90 = 11.7 mm/day, P95 = 20.1 mm/day, P99 = 43.6 mm/day
  scale: 20.0         # Based on P95 percentile
  w_min: 1.0          # CRITICAL FIX: Equal weighting for dry/wet (was 0.1 causing drizzle everywhere)
  w_max: 3.0          # Keep moderate (not aggressive 5.0)

  # Extra boost for extreme tail (P99+) - Moderately increased
  tail_boost: 3.0     # INCREASED from 2.0 (more extreme emphasis without being aggressive)

  # Mass conservation (keep small)
  lambda_mass: 0.005  # Light constraint

  # KL divergence - ULTRA-LOW to prevent posterior collapse
  beta_kl: 0.0005     # CRITICAL: 10x reduction from 0.005 (allow model to use latent z)
  warmup_epochs: 20   # INCREASED from 15 (slower, gentler warmup)

  p99_threshold: "from_thresholds_json"  # Will load P99=4.26

# Training configuration - Better convergence
train:
  epochs: 250           # INCREASED from 150 (more time to converge)
  batch_size: 64
  num_workers: 2
  lr: 0.0003
  weight_decay: 0.0005
  grad_clip: 1.0
  amp: true
  save_every: 20        # Save less frequently

  # Early stopping - More patient
  early_stopping_patience: 60       # INCREASED from 40 (give it more time)
  early_stopping_metric: "MAE_tail"  # Optimize for extremes
  early_stopping_min_delta: 0.01    # INCREASED from 0.001 (require meaningful improvement)

  # LR warmup - More gradual
  lr_warmup_epochs: 10  # INCREASED from 5 (gentler warmup)

  # Stratified sampling - See more heavy events
  use_stratified_sampling: true
  min_heavy_fraction: 0.4  # INCREASED from 0.2 (40% heavy days per batch)

# Learning rate scheduler - Better for long training
scheduler:
  type: "plateau"       # CHANGED from cosine (adaptive LR reduction)
  mode: "min"
  factor: 0.5           # Reduce LR by half when plateaued
  patience: 20          # Wait 20 epochs before reducing
  min_lr: 1.0e-6
  threshold: 0.01

# Validation
validation:
  val_every: 1
  log_every: 50

# Sampling
sampling:
  mode: "posterior"
  K: 5              # Generate 5 samples per heavy day
  days: "heavy_only"
  min_threshold: 0.1
  temperature: 1.0
  pixel_threshold: 0.1  # CRITICAL: Zero out drizzle below this threshold (mm/day)

# Device
device: "cuda"
seed: 42
