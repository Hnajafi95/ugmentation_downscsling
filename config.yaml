# Simplified Configuration - Single Unified Loss Objective
# Philosophy: ONE reconstruction loss (like SRDRN) + KL regularization
# Avoids multi-objective trade-offs!

# Data paths
data_root: "/scratch/user/u.hn319322/ondemand/Downscaling/cVAE_augmentation_v1"
outputs_root: "/scratch/user/u.hn319322/ondemand/Downscaling/cVAE_augmentation_v1/outputs/cvae_simplified"

# Static maps configuration
statics:
  use_land_sea: true
  use_dist_coast: true
  use_elevation: false
  normalize_statics: true

# Model architecture
model:
  d_x: 64
  in_channels_X: 6
  d_y: 256
  in_channels_Y: 1
  static_channels: 2
  d_z: 128  # Increased from 64 for better spatial pattern capacity
  H: 156
  W: 132
  base_filters: 96  # Increased from 64 to improve spatial learning

# Loss function - SIMPLIFIED!
loss:
  type: "simplified"  # Use SimplifiedCVAELoss instead of CVAELoss

  # Intensity weighting - Based on data analysis (P90 = 11.7 mm/day)
  # P90 = 11.7 mm/day, P95 = 20.1 mm/day, P99 = 43.6 mm/day
  scale: 11.7         # Based on P90 recommendation from analyze_parameters.py
  w_min: 0.1          # Min weight for light rain
  w_max: 2.0          # Reduced from 3.0 to avoid over-emphasis on extremes

  # Extra boost for extreme tail (P99+)
  tail_boost: 1.5     # Moderate boost for P99+ pixels to improve extreme precipitation

  # Mass conservation (optional, small weight)
  lambda_mass: 0.005  # Small weight for physical consistency

  # Spatial gradient loss (NEW - encourages spatial pattern matching)
  lambda_gradient: 0.1  # Weight for gradient/edge preservation loss

  # KL divergence (required for VAE)
  beta_kl: 0.01       # Reduced from 0.05 with spatial injection architecture (more freedom for diversity)
  warmup_epochs: 30   # Gradual warmup to avoid posterior collapse

  p99_threshold: "from_thresholds_json"  # Will load P99=4.26

# Training configuration
train:
  epochs: 250           # Increased from 150 to allow more training time
  batch_size: 64
  num_workers: 2
  lr: 0.0003            # Increased from 0.0001 for faster convergence
  weight_decay: 0.0005  # Reduced from 0.001 to allow more spatial complexity
  grad_clip: 1.0
  amp: true
  save_every: 10

  # Early stopping
  early_stopping_patience: 60  # Increased from 40 to prevent premature stopping
  early_stopping_metric: "MAE_tail"  # Optimize directly for extremes!
  early_stopping_min_delta: 0.001    # Minimum improvement to count

  # LR warmup - gradually increase LR at start
  lr_warmup_epochs: 5     # Warmup for first 5 epochs

  # Stratified sampling - ensures each batch has heavy precipitation days
  use_stratified_sampling: true   # Enable stratified batching
  min_heavy_fraction: 0.2         # 20% of each batch will be heavy days

# Learning rate scheduler
scheduler:
  type: "cosine"
  T_max: 250  # Updated to match new epoch count
  eta_min: 0.000001

# Validation
validation:
  val_every: 1
  log_every: 50

# Sampling
sampling:
  mode: "prior"  # Use prior - with fixed KL divergence, prior sampling should work
  K: 5
  days: "heavy_only"
  min_threshold: 0.1
  temperature: 0.7  # Reduced from 1.0 to better match learned posterior scale
  # pixel_threshold: 1.0  # REMOVED - ReLU fix allows model to naturally predict dry conditions

# Device
device: "cuda"
# seed: 42  # REMOVED - was making samples deterministic!
